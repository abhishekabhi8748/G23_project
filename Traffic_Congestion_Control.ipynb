{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3186f4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AJAY\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\AJAY\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\AJAY\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "The Count of the vehicles is: 8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from util import traffic_Signal\n",
    "\n",
    "# Load the pre-trained models.\n",
    "background_object = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "emergency_model = load_model('config/emergency_identification.h5')\n",
    "\n",
    "# Load the first video.\n",
    "video1 = cv2.VideoCapture('dataset/carsvid.wmv')\n",
    "\n",
    "# Load the second video.\n",
    "video2 = cv2.VideoCapture('dataset/carsvid.wmv')\n",
    "\n",
    "while True:\n",
    "    # Read a new frame from the first video.\n",
    "    detected_cars = set()\n",
    "    ret1, frame1 = video1.read()\n",
    "\n",
    "    # Read a new frame from the second video.\n",
    "    ret2, frame2 = video2.read()\n",
    "\n",
    "    # Check if frames are not read correctly.\n",
    "    if not ret1 or not ret2:\n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "    # Apply the background object on the frame to get the segmented mask for the first video.\n",
    "    fg_mask1 = background_object.apply(frame1)\n",
    "\n",
    "    # Perform thresholding to get rid of the shadows.\n",
    "    _, fg_mask1 = cv2.threshold(fg_mask1, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply some morphological operations to make sure you have a good mask.\n",
    "    fg_mask1 = cv2.erode(fg_mask1, None, iterations=1)\n",
    "    fg_mask1 = cv2.dilate(fg_mask1, None, iterations=2)\n",
    "\n",
    "    # Detect contours in the frame.\n",
    "    contours1, _ = cv2.findContours(fg_mask1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a copy of the frame to draw bounding boxes around the detected vehicles for the first video.\n",
    "    frame_copy1 = frame1.copy()\n",
    "\n",
    "    # Loop over each contour found in the frame.\n",
    "    for cnt1 in contours1:\n",
    "        # Make sure the contour area is somewhat higher than some threshold to make sure it's a vehicle and not some noise.\n",
    "        if cv2.contourArea(cnt1) > 400:\n",
    "            car_id = tuple(cv2.boundingRect(cnt1))\n",
    "            # Retrieve the bounding box coordinates from the contour.\n",
    "            if car_id not in detected_cars:\n",
    "                # Add the car to the set of detected cars.\n",
    "                detected_cars.add(car_id)\n",
    "\n",
    "                # Retrieve the bounding box coordinates from the contour.\n",
    "                x, y, width, height = car_id\n",
    "\n",
    "                # Draw a bounding box around the car.\n",
    "                cv2.rectangle(frame_copy1, (x, y), (x + width, y + height), (0, 0, 255), 2)\n",
    "\n",
    "                # Write Car Detected near the bounding box drawn.\n",
    "                cv2.putText(frame_copy1, f'Car Detected {len(detected_cars)}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "                            (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Apply the background object on the frame to get the segmented mask for the second video.\n",
    "    fg_mask2 = background_object.apply(frame2)\n",
    "\n",
    "    # Perform thresholding to get rid of the shadows.\n",
    "    _, fg_mask2 = cv2.threshold(fg_mask2, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply some morphological operations to make sure you have a good mask.\n",
    "    fg_mask2 = cv2.erode(fg_mask2, None, iterations=1)\n",
    "    fg_mask2 = cv2.dilate(fg_mask2, None, iterations=2)\n",
    "\n",
    "    # Detect contours in the frame.\n",
    "    contours2, _ = cv2.findContours(fg_mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a copy of the frame to draw bounding boxes around the detected vehicles for the second video.\n",
    "    frame_copy2 = frame2.copy()\n",
    "\n",
    "    # Loop over each contour found in the frame.\n",
    "    for cnt2 in contours2:\n",
    "        # Make sure the contour area is somewhat higher than some threshold to make sure it's a vehicle and not some noise.\n",
    "        if cv2.contourArea(cnt2) > 400:\n",
    "            # Retrieve the bounding box coordinates from the contour.\n",
    "            x2, y2, width2, height2 = cv2.boundingRect(cnt2)\n",
    "\n",
    "            # Extract the region of interest (ROI) for the emergency vehicle classification.\n",
    "            roi2 = frame2[y2:y2 + height2, x2:x2 + width2]\n",
    "\n",
    "            # Resize the ROI to match the expected input shape of the model.\n",
    "            input_roi2 = cv2.resize(roi2, (350, 350)) / 255.0  # Adjust the size based on your model's input size\n",
    "\n",
    "            # Perform prediction using the loaded emergency identification model.\n",
    "            prediction2 = emergency_model.predict(np.expand_dims(input_roi2, axis=0))\n",
    "\n",
    "            # Assuming the model outputs a probability score, you can set a threshold for identification.\n",
    "            threshold2 = 0.95\n",
    "            if prediction2[0] > threshold2:\n",
    "                cv2.rectangle(frame_copy2, (x2, y2), (x2 + width2, y2 + height2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame_copy2, 'Emergency Vehicle Detected', (x2, y2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                            (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.rectangle(frame_copy2, (x2, y2), (x2 + width2, y2 + height2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame_copy2, 'Non-Emergency Vehicle Detected', (x2, y2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                            (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Resize both frames to have the same height.\n",
    "    common_height = min(frame_copy1.shape[0], frame_copy2.shape[0])\n",
    "    frame_copy1 = cv2.resize(frame_copy1, (int(frame_copy1.shape[1] * common_height / frame_copy1.shape[0]), common_height))\n",
    "    frame_copy2 = cv2.resize(frame_copy2, (int(frame_copy2.shape[1] * common_height / frame_copy2.shape[0]), common_height))\n",
    "\n",
    "    # Stack the frames side by side for display.\n",
    "    stacked_frames = np.hstack((frame_copy1, frame_copy2))\n",
    "\n",
    "    # Display the stacked frames.\n",
    "    cv2.imshow('Vehicle and Emergency Identification', cv2.resize(stacked_frames, None, fx=0.5, fy=0.5))\n",
    "\n",
    "    # Wait until a key is pressed.\n",
    "    k = cv2.waitKey(50) & 0xFF\n",
    "\n",
    "    # Check if 'q' key is pressed.\n",
    "    if k == ord('q'):\n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "print(f'The Count of the vehicles is: {len(detected_cars)}')\n",
    "        \n",
    "# Release the VideoCapture objects.\n",
    "video1.release()\n",
    "video2.release()\n",
    "\n",
    "# Close the window.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbdc748d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the Seconds for Green signal\n",
    "count = len(detected_cars)\n",
    "seconds = min(count +(count/2)+10 , 90);\n",
    "int(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecaedea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Signal Switching Phase\u001b[0m\n",
      "\u001b[1m\n",
      "\u001b[99mOPENING LANE-1: \u001b[0m\n",
      "----------------------------------------------------------------------------------\n",
      "Lane 1                Lane 2                Lane 3                Lane 4\n",
      "  âšª                   ðŸ”´                    ðŸ”´                   ðŸ”´\n",
      "  âšª                   âšª                    âšª                   âšª\n",
      "  ðŸŸ¢                   âšª                    âšª                   âšª\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "\u001b[99mLANE-1 OPENED !\u001b[0m\n",
      "\n",
      " Calculating Signal Open-Close Timing...\n",
      "\u001b[0m\n",
      "\u001b[99mLANE-1 will CLOSE after 19 seconds \u001b[0m\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.\u001b[99m.----------------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "\u001b[99mCLOSING LANE-1: \u001b[0m\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Lane 1                Lane 2                Lane 3                Lane 4\n",
      "  ðŸ”´                   ðŸ”´                    ðŸ”´                   ðŸ”´\n",
      "  âšª                   âšª                    âšª                   âšª\n",
      "  âšª                   âšª                    âšª                   âšª\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[99mLANE-1\u001b[0m is now CLOSED \n"
     ]
    }
   ],
   "source": [
    "traffic_Signal.traffic_signal(1,int(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1f82d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
